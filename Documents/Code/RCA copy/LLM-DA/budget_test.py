#!/usr/bin/env python3

import os
import json
import shutil
from utils import load_json_data, save_json_data

def create_tiny_dataset():

    try:
        # è¯»å–åŸå§‹æ•°æ®
        with open("datasets/icews14/train.txt", "r") as f:
            lines = f.readlines()
        
        # åªå–å‰50è¡Œ
        tiny_lines = lines[:50]
        
        # åˆ›å»ºtinyæ•°æ®é›†ç›®å½•
        os.makedirs("datasets/icews14_tiny", exist_ok=True)
        
        # ä¿å­˜tinyè®­ç»ƒæ•°æ®
        with open("datasets/icews14_tiny/train.txt", "w") as f:
            f.writelines(tiny_lines)
        
        # å¤åˆ¶å¿…è¦æ–‡ä»¶
        for file in ["relation2id.json", "entity2id.json", "ts2id.json"]:
            shutil.copy(f"datasets/icews14/{file}", f"datasets/icews14_tiny/{file}")
        
        # åˆ›å»ºtinyçš„éªŒè¯å’Œæµ‹è¯•é›† (å„10æ¡)
        with open("datasets/icews14_tiny/valid.txt", "w") as f:
            f.writelines(lines[50:60])
        
        with open("datasets/icews14_tiny/test.txt", "w") as f:
            f.writelines(lines[60:70])
        
        print(f"è¶…å°å‹æ•°æ®é›†åˆ›å»ºæˆåŠŸ!")
        print(f"   - è®­ç»ƒæ•°æ®: {len(tiny_lines)} æ¡")
        print(f"   - éªŒè¯æ•°æ®: 10 æ¡")
        print(f"   - æµ‹è¯•æ•°æ®: 10 æ¡")
        print(f"   - æ€»æ•°æ®é‡: {len(tiny_lines) + 20} æ¡")
        
        return True
        
    except Exception as e:
        print(f"{e}")
        return False

def test_llm_with_limit():
    
    try:
        from llms import get_registed_model
        
        class Args:
            def __init__(self):
                self.model_name = "gpt-4o-mini"  # æœ€ä¾¿å®œçš„æ¨¡å‹
                self.retry = 1  # åªé‡è¯•1æ¬¡
        
        args = Args()
        llm = get_registed_model(args.model_name)
        llm = llm(args)
        llm.prepare_for_inference()
        
        # æç®€æµ‹è¯•prompt
        test_prompt = "ç”Ÿæˆä¸€ä¸ªæ—¶åºè§„åˆ™: Make_statement(X0,X1,T1)<-Consult(X0,X1,T0)"
        result = llm.generate_sentence(test_prompt)
        
        print("LLMè¿æ¥æˆåŠŸ!")
        print(f"æ¨¡å‹: {args.model_name}")
        print(f"ç»“æœ: {result[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"LLMæµ‹è¯•å¤±è´¥: {e}")
        return False

def create_budget_config():
    
    config = {
        "model_name": "gpt-4o-mini",
        "max_rules_per_relation": 2,  # æ¯ä¸ªå…³ç³»æœ€å¤šç”Ÿæˆ2ä¸ªè§„åˆ™
        "max_relations": 5,  # åªå¤„ç†5ä¸ªå…³ç³»
        "max_iterations": 1,  # åªè¿­ä»£1æ¬¡
        "max_samples": 3,  # æœ€å¤šé‡‡æ ·3æ¬¡
        "timeout": 30,  # 30ç§’è¶…æ—¶
        "retry": 1  # åªé‡è¯•1æ¬¡
    }
    
    with open("budget_config.json", "w") as f:
        json.dump(config, f, indent=2)
    
    for key, value in config.items():
        print(f"   - {key}: {value}")
    
    return config

def estimate_cost():
    """ä¼°ç®—æˆæœ¬"""
    print("\n" + "=" * 50)
    print("æˆæœ¬ä¼°ç®—")
    print("=" * 50)
    
    # GPT-4o-mini ä»·æ ¼ (2024å¹´)
    input_cost_per_1k = 0.00015  # $0.15 per 1M tokens
    output_cost_per_1k = 0.0006  # $0.60 per 1M tokens
    
    # ä¼°ç®—tokenä½¿ç”¨é‡
    estimated_input_tokens = 1000  # æ¯æ¬¡è°ƒç”¨çº¦1000 tokens
    estimated_output_tokens = 200  # æ¯æ¬¡è¾“å‡ºçº¦200 tokens
    
    # è°ƒç”¨æ¬¡æ•°
    max_calls = 10 
    
    total_input_cost = (estimated_input_tokens / 1000) * input_cost_per_1k * max_calls
    total_output_cost = (estimated_output_tokens / 1000) * output_cost_per_1k * max_calls
    total_cost = total_input_cost + total_output_cost
    
    print(f"   - æœ€å¤§APIè°ƒç”¨æ¬¡æ•°: {max_calls}")
    print(f"   - é¢„ä¼°è¾“å…¥tokens: {estimated_input_tokens * max_calls:,}")
    print(f"   - é¢„ä¼°è¾“å‡ºtokens: {estimated_output_tokens * max_calls:,}")
    print(f"   - é¢„ä¼°æ€»æˆæœ¬: ${total_cost:.4f} (çº¦Â¥{total_cost * 7:.2f})")

def create_budget_commands():
    
    commands = [
        "# 1. è§„åˆ™é‡‡æ · (æç®€å‚æ•°)",
        "python3 rule_sampler.py -d icews14_tiny -m 2 -n 3 -p 1 -s 1 --is_relax_time No",
        "",
        "# 2. è§„åˆ™ç”Ÿæˆ (é™åˆ¶å‚æ•°)",
        "python3 Iteration_reasoning.py -d icews14_tiny --model_name gpt-4o-mini -f 2 -l 1 --is_rel_name Yes",
        "",
        "# 3. è§„åˆ™æ’åº",
        "python3 rank_rule.py -p copy_gpt-4o-mini-top-0-f-2-l-1 -d icews14_tiny",
        "",
        "# 4. æ¨ç†æµ‹è¯•",
        "python3 reasoning.py -p copy_gpt-4o-mini-top-0-f-2-l-1 -d icews14_tiny",
        "",
        "# 5. è¯„ä¼°",
        "python3 evaluate.py -d icews14_tiny -c 'llm_test_apply_all_conf_cands_r[1,2,3]_w0_score_12[0.1,0.5,\\'TLogic\\',0.0,0.01,0]_top_20_et_origin.json' --graph_reasoning_type TiRGN --rule_weight 0.9"
    ]
    
    print("ğŸ’¡ å»ºè®®çš„è¿è¡Œé¡ºåº:")
    for cmd in commands:
        print(cmd)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("budget_commands.sh", "w") as f:
        f.write("#!/bin/bash\n")
        for cmd in commands:
            if not cmd.startswith("#") and cmd.strip():
                f.write(cmd + "\n")

def main():

    # 1. åˆ›å»ºè¶…å°å‹æ•°æ®é›†
    if not create_tiny_dataset():
        return
    
    # 2. æµ‹è¯•LLMè¿æ¥
    if not test_llm_with_limit():
        print("LLMè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®")
        return
    
    # 3. åˆ›å»ºçœé’±é…ç½®
    create_budget_config()
    
    # 4. ä¼°ç®—æˆæœ¬
    estimate_cost()
    
    # 5. ç”Ÿæˆè¿è¡Œå‘½ä»¤
    create_budget_commands()

if __name__ == "__main__":
    main()
