#!/usr/bin/env python3
import argparse, json, os
from kg_rca.builder import build_knowledge_graph, tkg_from_openrca
import pandas as pd
from kg_rca.timeutil import extract_and_convert_datetime, parse_opencra_timestamp
from pathlib import Path
from kg_rca.util import export_trimmed_csv

def get_data_paths(dataset: str, data_root: str = None):
    """è·å–æ•°æ®è·¯å¾„ï¼Œæ”¯æŒç¯å¢ƒå˜é‡å’Œç›¸å¯¹è·¯å¾„"""
    if data_root is None:
        data_root = os.getenv('KG_RCA_DATA_ROOT', './data')
    
    # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
    if not os.path.isabs(data_root):
        data_root = os.path.abspath(data_root)
    
    init_file = os.path.join(data_root, dataset, 'query.csv')
    telemetry_folder = os.path.join(data_root, dataset, 'telemetry')
    
    return init_file, telemetry_folder

def validate_paths(init_file: str, telemetry_folder: str):
    """éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(init_file):
        raise FileNotFoundError(f'Query file not found: {init_file}')
    
    if not os.path.exists(telemetry_folder):
        raise FileNotFoundError(f'Telemetry folder not found: {telemetry_folder}')
    
    print(f"âœ… Data paths validated:")
    print(f"   Query file: {init_file}")
    print(f"   Telemetry folder: {telemetry_folder}")

def main():
    ap = argparse.ArgumentParser(description="Build Knowledge Graph from traces/logs/metrics (+ causal discovery)")
    ap.add_argument("--dataset", type=str, default="Bank", help="Dataset name (Bank, Telecom, etc.)")
    ap.add_argument("--data-root", type=str, default=None, help="Data root directory (default: ./data)")
    ap.add_argument("--problem_number", type=int, default=1, help="Number of problems to process")
    ap.add_argument("--incident-id", type=str, default="openrca_1", help="Incident identifier")
    ap.add_argument("--outdir", type=str, default="outputs", help="Output directory")
    ap.add_argument("--no-causal", action="store_true", help="Disable causal discovery on metrics")
    ap.add_argument("--pc-alpha", type=float, default=0.05, help="PC test alpha (default 0.05)")
    ap.add_argument("--resample", type=str, default="60S", help="Resample rule for metrics (e.g., 60S, 5T)")
    args = ap.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.outdir, exist_ok=True)

    # è·å–æ•°æ®è·¯å¾„
    init_file, telemetry_folder = get_data_paths(args.dataset, args.data_root)
    
    # éªŒè¯è·¯å¾„
    validate_paths(init_file, telemetry_folder)

    # è¯»å–é—®é¢˜æ•°æ®
    try:
        instruct_data = pd.read_csv(init_file)['instruction'][1:args.problem_number + 1]
        scoring_data = pd.read_csv(init_file)['scoring_points'][1:args.problem_number + 1]
        print(f"ğŸ“Š Loaded {len(instruct_data)} problems from {init_file}")
    except Exception as e:
        print(f"âŒ Error reading query file: {e}")
        return

    # å¤„ç†æ¯ä¸ªé—®é¢˜
    for i, item in enumerate(instruct_data):
        print(f"\nğŸ”„ Processing problem {i+1}/{len(instruct_data)}")
        
        try:
            time_dict = extract_and_convert_datetime(item)
            data_time = time_dict['formatted_date']
            start_time = time_dict['start_timestamp']
            end_time = time_dict['end_timestamp']
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            trace_path = os.path.join(telemetry_folder, data_time, 'trace', 'trace_span.csv')
            metrics_path = os.path.join(telemetry_folder, data_time, 'metric', 'metric_container.csv')
            log_path = os.path.join(telemetry_folder, data_time, 'log', 'log_service.csv')
            
            print(f"   ğŸ“ Data time: {data_time}")
            print(f"   ğŸ“ Trace: {trace_path}")
            print(f"   ğŸ“ Metrics: {metrics_path}")
            print(f"   ğŸ“ Logs: {log_path}")
            
            # éªŒè¯æ•°æ®æ–‡ä»¶å­˜åœ¨
            for path in [trace_path, metrics_path, log_path]:
                if not os.path.exists(path):
                    print(f"   âš ï¸  Warning: {path} not found")
            
            # ä½¿ç”¨ tkg_from_openrca å¤„ç†
            print(f"   ğŸ”„ Running tkg_from_openrca...")
            test_list, top_info = tkg_from_openrca(
                traces_path=trace_path,
                logs_path=log_path,
                metrics_path=metrics_path,
                incident_id=args.incident_id,
                window={"start": start_time, "end": end_time} if (start_time or end_time) else None,
            )
            
            print(f"   ğŸ“Š Generated {len(test_list)} time slices")
            
            # å¯¼å‡ºç»“æœ
            for ts_time, kg in test_list:
                time = parse_opencra_timestamp(str(ts_time))
                time_str = time.strftime("%H-%M-%S")
                
                # åˆ›å»ºè¾“å‡ºç›®å½•
                base = Path(args.outdir) / args.dataset / data_time / time_str
                base.mkdir(parents=True, exist_ok=True)
                
                # è¾“å‡ºæ–‡ä»¶è·¯å¾„
                graphml = base / f"{args.incident_id}.graphml"
                nodes_csv = base / f"{args.incident_id}.nodes.csv"
                edges_csv = base / f"{args.incident_id}.edges.csv"
                summary_path = base / f"{args.incident_id}.summary.json"
                
                # å¯¼å‡ºæ•°æ®
                kg.to_csv(nodes_csv, edges_csv)
                with open(summary_path, "w") as f:
                    json.dump(kg.summary(), f, indent=2, default=str)
                
                try:
                    kg.to_graphml(graphml)
                except Exception as e:
                    print(f"   âš ï¸  Warning: Could not export GraphML: {e}")
                
                print(f"   ğŸ“¤ Exported to: {base}")
                print(f"      - Nodes: {nodes_csv}")
                print(f"      - Edges: {edges_csv}")
                print(f"      - Summary: {summary_path}")
                
                # å¯¼å‡ºä¿®å‰ªåçš„CSV
                try:
                    nodes_csv_trim, edges_csv_trim = export_trimmed_csv(kg, nodes_csv, edges_csv)
                    print(f"      - Trimmed: {nodes_csv_trim}, {edges_csv_trim}")
                except Exception as e:
                    print(f"   âš ï¸  Warning: Could not export trimmed CSV: {e}")
                
                # æ‰“å°å›¾è°±æ‘˜è¦
                summary = kg.summary()
                print(f"   ğŸ“Š Graph summary: {summary['nodes']} nodes, {summary['edges']} edges")
        
        except Exception as e:
            print(f"   âŒ Error processing problem {i+1}: {e}")
            continue
    
    print(f"\nâœ… Processing complete!")

if __name__ == "__main__":
    main()
