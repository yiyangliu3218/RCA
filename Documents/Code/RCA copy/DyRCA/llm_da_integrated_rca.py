#!/usr/bin/env python3
"""
çœŸæ­£ç»“åˆ LLM-DA æ—¶åºéšæœºæ¸¸èµ°çš„åŠ¨æ€ RCA ç³»ç»Ÿ
"""
import sys
import os
import time
import json
import numpy as np
from typing import Dict, List, Any, Tuple
from collections import defaultdict, deque

# Add project paths
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
KG_RCA_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "KG-RCA"))
if KG_RCA_DIR not in sys.path:
    sys.path.insert(0, KG_RCA_DIR)
LLM_DA_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "LLM-DA"))
if LLM_DA_DIR not in sys.path:
    sys.path.insert(0, LLM_DA_DIR)

from kg_rca.builder import build_knowledge_graph
from kg_rca.graph import KnowledgeGraph
from DyRCA.walks.adapter import export_edges_for_temporal_walk, _node_id_map, RELATION_TO_ID, ID_TO_RELATION
from temporal_walk import Temporal_Walk, store_neighbors, store_edges


class LLMDAIntegratedRCA:
    """
    çœŸæ­£ç»“åˆ LLM-DA æ—¶åºéšæœºæ¸¸èµ°çš„åŠ¨æ€ RCA ç³»ç»Ÿ
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. ä»æ–°å¼‚å¸¸å‡ºå‘ï¼Œä½¿ç”¨ LLM-DA çš„æ—¶åºéšæœºæ¸¸èµ°æ‰¾åˆ°å¯èƒ½çš„æ ¹å› è·¯å¾„
    2. åˆ©ç”¨ Walk å‡å°‘è®¡ç®—é‡ï¼šåªåˆ†æå˜åŒ–çš„éƒ¨åˆ†ï¼Œä¸é‡å»ºæ•´ä¸ªå›¾
    3. Agent åŸºäº Walk ç»“æœæ™ºèƒ½å†³ç­–ä¸‹ä¸€æ­¥è°ƒæŸ¥
    """
    
    def __init__(self):
        # å›¾çŠ¶æ€
        self.kg = KnowledgeGraph()
        self.node_mapping = {}  # åŸå§‹èŠ‚ç‚¹ID -> æ•´æ•°IDæ˜ å°„
        self.inv_node_mapping = {}  # æ•´æ•°ID -> åŸå§‹èŠ‚ç‚¹IDæ˜ å°„
        
        # LLM-DA ç»„ä»¶
        self.temporal_walker = None
        self.learned_rules = {}
        
        # åŠ¨æ€çŠ¶æ€
        self.recent_anomalies = deque(maxlen=100)
        self.service_states = {}
        self.walk_cache = {}
        
        # æ—¶é—´çª—å£
        self.window_size = 300  # 5åˆ†é’Ÿ
        self.last_update = time.time()
    
    def initialize_with_sample_data(self):
        """ä½¿ç”¨ç¤ºä¾‹æ•°æ®åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿ...")
        
        # 1. æ„å»ºåˆå§‹çŸ¥è¯†å›¾è°±
        self.kg = build_knowledge_graph(
            traces_path="KG-RCA/sample_data/traces.json",
            logs_path="KG-RCA/sample_data/logs.jsonl",
            metrics_path="KG-RCA/sample_data/metrics.csv",
            incident_id="llm_da_integrated",
            window=None,
            enable_causal=False,
            resample_rule="60S",
        )
        
        # 2. å»ºç«‹èŠ‚ç‚¹æ˜ å°„
        uid_to_int, int_to_uid = _node_id_map(self.kg.G)
        self.node_mapping = uid_to_int
        self.inv_node_mapping = int_to_uid
        
        # 3. å¯¼å‡ºè¾¹æ•°æ®ç»™ LLM-DA
        edges = export_edges_for_temporal_walk(self.kg.G)
        
        # 4. è½¬æ¢ä¸º LLM-DA æ ¼å¼
        quads = self._convert_to_llm_da_format(edges)
        
        # 5. åˆå§‹åŒ– LLM-DA æ—¶åºéšæœºæ¸¸èµ°
        inv_relation_id = self._create_inv_relation_mapping()
        self.temporal_walker = Temporal_Walk(
            learn_data=quads,
            inv_relation_id=inv_relation_id,
            transition_distr="exp"  # ä½¿ç”¨æŒ‡æ•°åˆ†å¸ƒ
        )
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"   - å…³ç³»æ•°é‡: {len(self.temporal_walker.edges)}")
        for rel_id, edges in self.temporal_walker.edges.items():
            print(f"     å…³ç³» {rel_id}: {len(edges)} æ¡è¾¹")
        
        print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   - å›¾è°±èŠ‚ç‚¹: {self.kg.G.number_of_nodes()}")
        print(f"   - å›¾è°±è¾¹: {self.kg.G.number_of_edges()}")
        print(f"   - æ—¶åºæ¸¸èµ°æ•°æ®: {len(quads)} æ¡è¾¹")
    
    def _convert_to_llm_da_format(self, edges: Dict[int, np.ndarray]) -> np.ndarray:
        """å°†æˆ‘ä»¬çš„è¾¹æ•°æ®è½¬æ¢ä¸º LLM-DA çš„å››å…ƒç»„æ ¼å¼ [head, relation, tail, timestamp]"""
        quads = []
        
        for rel_id, edge_array in edges.items():
            for edge in edge_array:
                head, relation, tail, timestamp = edge
                quads.append([head, relation, tail, timestamp])
        
        return np.array(quads, dtype=np.int64)
    
    def _create_inv_relation_mapping(self) -> Dict[int, int]:
        """åˆ›å»ºé€†å…³ç³»æ˜ å°„"""
        inv_mapping = {}
        for rel_name, rel_id in RELATION_TO_ID.items():
            # ç®€å•çš„é€†å…³ç³»æ˜ å°„ï¼ˆå®é™…åº”è¯¥æ›´å¤æ‚ï¼‰
            inv_mapping[rel_id] = rel_id + 1000  # é€†å…³ç³»ID = åŸID + 1000
        return inv_mapping
    
    def process_new_anomaly(self, anomaly: Dict[str, Any]):
        """
        å¤„ç†æ–°å¼‚å¸¸ï¼š
        1. ä½¿ç”¨ LLM-DA æ—¶åºéšæœºæ¸¸èµ°æ‰¾åˆ°å¯èƒ½çš„æ ¹å› è·¯å¾„
        2. æ›´æ–° Walk ç¼“å­˜
        3. Agent å†³ç­–
        """
        print(f"ğŸš¨ å¤„ç†æ–°å¼‚å¸¸: {anomaly}")
        
        # 1. æ‰¾åˆ°å¼‚å¸¸å¯¹åº”çš„æ•´æ•°èŠ‚ç‚¹ID
        anomaly_node_id = self._find_anomaly_node_id(anomaly)
        if anomaly_node_id is None:
            print("   âŒ æ— æ³•æ‰¾åˆ°å¼‚å¸¸èŠ‚ç‚¹")
            return
        
        # 2. ä½¿ç”¨ LLM-DA æ—¶åºéšæœºæ¸¸èµ°
        root_cause_paths = self._llm_da_temporal_walk(anomaly_node_id)
        
        # 3. æ›´æ–° Walk ç¼“å­˜
        self._update_walk_cache(anomaly, root_cause_paths)
        
        # 4. Agent å†³ç­–
        self._agent_decision(anomaly, root_cause_paths)
    
    def _find_anomaly_node_id(self, anomaly: Dict[str, Any]) -> int:
        """æ‰¾åˆ°å¼‚å¸¸å¯¹åº”çš„æ•´æ•°èŠ‚ç‚¹ID"""
        service = anomaly.get('service')
        anomaly_type = anomaly.get('type')
        
        # åœ¨å›¾ä¸­æŸ¥æ‰¾å¯¹åº”çš„èŠ‚ç‚¹
        for node_id, data in self.kg.G.nodes(data=True):
            if (data.get('type') in ('LogEvent', 'MetricEvent') and 
                data.get('service') == service):
                return self.node_mapping.get(node_id)
        
        return None
    
    def _llm_da_temporal_walk(self, start_node_id: int, max_length: int = 3) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ LLM-DA æ—¶åºéšæœºæ¸¸èµ°æ‰¾åˆ°æ ¹å› è·¯å¾„
        
        æ ¸å¿ƒä»·å€¼ï¼š
        1. ä»å¼‚å¸¸èŠ‚ç‚¹å‡ºå‘ï¼Œæ²¿ç€æ—¶åºçº¦æŸçš„è·¯å¾„èµ°
        2. æ‰¾åˆ°å¯èƒ½çš„æ ¹å› èŠ‚ç‚¹
        3. è¿”å›å®Œæ•´çš„ä¼ æ’­è·¯å¾„
        """
        print(f"ğŸ” LLM-DA æ—¶åºæ¸¸èµ° from node {start_node_id}")
        
        root_cause_paths = []
        
        # å°è¯•ä¸åŒé•¿åº¦çš„æ¸¸èµ°
        for L in range(2, max_length + 1):
            print(f"   å°è¯•é•¿åº¦ {L} çš„æ¸¸èµ°...")
            
            # ä½¿ç”¨ LLM-DA çš„ sample_walk æ–¹æ³•
            try:
                # é€‰æ‹©ä¸€ä¸ªå…³ç³»å¼€å§‹æ¸¸èµ°
                for rel_id in RELATION_TO_ID.values():
                    # æ£€æŸ¥è¯¥å…³ç³»æ˜¯å¦æœ‰è¾¹
                    if rel_id not in self.temporal_walker.edges or len(self.temporal_walker.edges[rel_id]) == 0:
                        continue
                    
                    walk_successful, walk = self.temporal_walker.sample_walk(
                        L=L,
                        rel_idx=rel_id,
                        use_relax_time=False
                    )
                    
                    if walk_successful and walk:
                        # æ£€æŸ¥æ¸¸èµ°æ˜¯å¦ä»æˆ‘ä»¬çš„å¼‚å¸¸èŠ‚ç‚¹å¼€å§‹
                        entities = walk.get('entities', [])
                        if entities and entities[0] == start_node_id:
                            path_info = self._analyze_walk_path(walk)
                            if path_info:
                                root_cause_paths.append(path_info)
                                print(f"     âœ… æ‰¾åˆ°è·¯å¾„: {path_info['path']}")
            
            except Exception as e:
                print(f"     âŒ æ¸¸èµ°å¤±è´¥: {e}")
                continue
        
        return root_cause_paths
    
    def _analyze_walk_path(self, walk: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ¸¸èµ°è·¯å¾„ï¼Œæå–æ ¹å› ä¿¡æ¯"""
        if not walk:
            return None
        
        # æå–è·¯å¾„ä¸­çš„èŠ‚ç‚¹å’Œå…³ç³»
        entities = walk.get('entities', [])
        relations = walk.get('relations', [])
        timestamps = walk.get('timestamps', [])
        
        # è½¬æ¢ä¸ºåŸå§‹èŠ‚ç‚¹ID
        original_path = []
        for node_id in entities:
            original_node = self.inv_node_mapping.get(node_id)
            if original_node:
                original_path.append(original_node)
        
        # æ‰¾åˆ°å¯èƒ½çš„æ ¹å› èŠ‚ç‚¹ï¼ˆè·¯å¾„ä¸­çš„æœåŠ¡èŠ‚ç‚¹ï¼‰
        root_cause_candidates = []
        for node_id in entities:
            original_node = self.inv_node_mapping.get(node_id)
            if original_node and self.kg.G.nodes[original_node].get('type') == 'Service':
                root_cause_candidates.append(original_node)
        
        return {
            'path': original_path,
            'root_cause_candidates': root_cause_candidates,
            'path_length': len(entities),
            'confidence': self._calculate_path_confidence(walk)
        }
    
    def _calculate_path_confidence(self, walk: Dict[str, Any]) -> float:
        """è®¡ç®—è·¯å¾„çš„ç½®ä¿¡åº¦"""
        if not walk:
            return 0.0
        
        entities = walk.get('entities', [])
        timestamps = walk.get('timestamps', [])
        
        if not entities or not timestamps:
            return 0.0
        
        # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—ï¼šåŸºäºè·¯å¾„é•¿åº¦å’Œæ—¶é—´ä¸€è‡´æ€§
        length_factor = 1.0 / len(entities)  # è·¯å¾„è¶ŠçŸ­ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        
        # æ£€æŸ¥æ—¶é—´ä¸€è‡´æ€§
        time_consistency = 1.0
        for i in range(1, len(timestamps)):
            if timestamps[i] > timestamps[i-1]:  # æ—¶é—´åº”è¯¥éé€’å¢
                time_consistency *= 0.5
        
        return length_factor * time_consistency
    
    def _update_walk_cache(self, anomaly: Dict[str, Any], paths: List[Dict[str, Any]]):
        """æ›´æ–° Walk ç¼“å­˜"""
        service = anomaly.get('service')
        
        self.walk_cache[service] = {
            'timestamp': anomaly.get('timestamp', time.time()),
            'paths': paths,
            'confidence': max([p['confidence'] for p in paths]) if paths else 0.0,
            'root_cause_candidates': list(set([
                candidate for path in paths 
                for candidate in path['root_cause_candidates']
            ]))
        }
        
        print(f"   ğŸ“Š æ›´æ–°ç¼“å­˜: {service} -> {len(paths)} æ¡è·¯å¾„")
    
    def _agent_decision(self, anomaly: Dict[str, Any], paths: List[Dict[str, Any]]):
        """åŸºäº Walk ç»“æœçš„ Agent å†³ç­–"""
        print("ğŸ¤– Agent å†³ç­–")
        
        if not paths:
            print("   â†’ æ²¡æœ‰æ‰¾åˆ°æ ¹å› è·¯å¾„ï¼Œç»§ç»­ç›‘æ§")
            return
        
        # 1. åˆ†ææ‰€æœ‰è·¯å¾„ï¼Œæ‰¾åˆ°æœ€å¯èƒ½çš„æ ¹å› 
        all_candidates = defaultdict(int)
        for path in paths:
            for candidate in path['root_cause_candidates']:
                all_candidates[candidate] += path['confidence']
        
        if not all_candidates:
            print("   â†’ æ²¡æœ‰æ‰¾åˆ°æ ¹å› å€™é€‰")
            return
        
        # 2. é€‰æ‹©æœ€å¯èƒ½çš„æ ¹å› 
        best_candidate = max(all_candidates.items(), key=lambda x: x[1])
        root_cause_service, confidence = best_candidate
        
        print(f"   ğŸ¯ æœ€å¯èƒ½çš„æ ¹å› : {root_cause_service} (ç½®ä¿¡åº¦: {confidence:.3f})")
        
        # 3. ç”Ÿæˆè°ƒæŸ¥è®¡åˆ’
        self._generate_investigation_plan(root_cause_service, paths, confidence)
    
    def _generate_investigation_plan(self, root_cause_service: str, paths: List[Dict[str, Any]], confidence: float):
        """ç”Ÿæˆè°ƒæŸ¥è®¡åˆ’"""
        print(f"   ğŸ“‹ è°ƒæŸ¥è®¡åˆ’ for {root_cause_service}:")
        
        # æ‰¾åˆ°æ¶‰åŠè¯¥æœåŠ¡çš„è·¯å¾„
        relevant_paths = [p for p in paths if root_cause_service in p['root_cause_candidates']]
        
        for i, path in enumerate(relevant_paths[:3]):  # åªæ˜¾ç¤ºå‰3æ¡
            print(f"     {i+1}. è·¯å¾„: {' â†’ '.join(path['path'])}")
            print(f"        ç½®ä¿¡åº¦: {path['confidence']:.3f}")
            print(f"        é•¿åº¦: {path['path_length']}")
        
        # ç”Ÿæˆå…·ä½“çš„è°ƒæŸ¥å»ºè®®
        if confidence > 0.7:
            print(f"     ğŸ”¥ é«˜ç½®ä¿¡åº¦ï¼å»ºè®®ç«‹å³è°ƒæŸ¥ {root_cause_service}")
        elif confidence > 0.4:
            print(f"     âš ï¸  ä¸­ç­‰ç½®ä¿¡åº¦ï¼Œå»ºè®®ä¼˜å…ˆè°ƒæŸ¥ {root_cause_service}")
        else:
            print(f"     ğŸ“Š ä½ç½®ä¿¡åº¦ï¼Œå»ºè®®ç»§ç»­æ”¶é›†è¯æ®")


def simulate_llm_da_integrated_rca():
    """æ¨¡æ‹Ÿä½¿ç”¨ LLM-DA é›†æˆçš„åŠ¨æ€ RCA"""
    print("ğŸš€ å¯åŠ¨ LLM-DA é›†æˆçš„åŠ¨æ€ RCA ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rca = LLMDAIntegratedRCA()
    rca.initialize_with_sample_data()
    
    # æ¨¡æ‹Ÿæ–°å¼‚å¸¸
    anomalies = [
        {
            'service': 'frontend',
            'type': 'error',
            'severity': 'ERROR',
            'timestamp': time.time() - 60,
            'message': 'HTTP 500 error'
        },
        {
            'service': 'payment',
            'type': 'error', 
            'severity': 'ERROR',
            'timestamp': time.time() - 30,
            'message': 'Payment gateway timeout'
        },
        {
            'service': 'checkout',
            'type': 'error',
            'severity': 'ERROR', 
            'timestamp': time.time() - 10,
            'message': 'Checkout process failed'
        }
    ]
    
    # å¤„ç†æ¯ä¸ªå¼‚å¸¸
    for i, anomaly in enumerate(anomalies, 1):
        print(f"\nğŸ”„ === å¼‚å¸¸æ‰¹æ¬¡ {i} ===")
        rca.process_new_anomaly(anomaly)
        time.sleep(1)
    
    print(f"\nâœ… LLM-DA é›†æˆ RCA å®Œæˆ")
    print(f"ğŸ“Š æœ€ç»ˆçŠ¶æ€:")
    print(f"   - Walk ç¼“å­˜: {len(rca.walk_cache)} ä¸ªæœåŠ¡")
    print(f"   - èŠ‚ç‚¹æ˜ å°„: {len(rca.node_mapping)} ä¸ªèŠ‚ç‚¹")


if __name__ == "__main__":
    simulate_llm_da_integrated_rca()
