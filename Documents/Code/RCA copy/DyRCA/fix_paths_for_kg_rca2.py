#!/usr/bin/env python3
"""
ä¿®å¤ KG-RCA2 ä¸­çš„ç¡¬ç¼–ç è·¯å¾„é—®é¢˜
"""
import os
import sys
from pathlib import Path

def create_fixed_build_script():
    """åˆ›å»ºä¿®å¤åçš„ build_kg_for_openrca.py"""
    
    fixed_script = '''#!/usr/bin/env python3
import argparse, json, os
from kg_rca.builder import build_knowledge_graph, tkg_from_openrca
import pandas as pd
from kg_rca.timeutil import extract_and_convert_datetime, parse_opencra_timestamp
from pathlib import Path
from kg_rca.util import export_trimmed_csv

def get_data_paths(dataset: str, data_root: str = None):
    """è·å–æ•°æ®è·¯å¾„ï¼Œæ”¯æŒç¯å¢ƒå˜é‡å’Œç›¸å¯¹è·¯å¾„"""
    if data_root is None:
        data_root = os.getenv('KG_RCA_DATA_ROOT', './data')
    
    # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
    if not os.path.isabs(data_root):
        data_root = os.path.abspath(data_root)
    
    init_file = os.path.join(data_root, dataset, 'query.csv')
    telemetry_folder = os.path.join(data_root, dataset, 'telemetry')
    
    return init_file, telemetry_folder

def validate_paths(init_file: str, telemetry_folder: str):
    """éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(init_file):
        raise FileNotFoundError(f'Query file not found: {init_file}')
    
    if not os.path.exists(telemetry_folder):
        raise FileNotFoundError(f'Telemetry folder not found: {telemetry_folder}')
    
    print(f"âœ… Data paths validated:")
    print(f"   Query file: {init_file}")
    print(f"   Telemetry folder: {telemetry_folder}")

def main():
    ap = argparse.ArgumentParser(description="Build Knowledge Graph from traces/logs/metrics (+ causal discovery)")
    ap.add_argument("--dataset", type=str, default="Bank", help="Dataset name (Bank, Telecom, etc.)")
    ap.add_argument("--data-root", type=str, default=None, help="Data root directory (default: ./data)")
    ap.add_argument("--problem_number", type=int, default=1, help="Number of problems to process")
    ap.add_argument("--incident-id", type=str, default="openrca_1", help="Incident identifier")
    ap.add_argument("--outdir", type=str, default="outputs", help="Output directory")
    ap.add_argument("--no-causal", action="store_true", help="Disable causal discovery on metrics")
    ap.add_argument("--pc-alpha", type=float, default=0.05, help="PC test alpha (default 0.05)")
    ap.add_argument("--resample", type=str, default="60S", help="Resample rule for metrics (e.g., 60S, 5T)")
    args = ap.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.outdir, exist_ok=True)

    # è·å–æ•°æ®è·¯å¾„
    init_file, telemetry_folder = get_data_paths(args.dataset, args.data_root)
    
    # éªŒè¯è·¯å¾„
    validate_paths(init_file, telemetry_folder)

    # è¯»å–é—®é¢˜æ•°æ®
    try:
        instruct_data = pd.read_csv(init_file)['instruction'][1:args.problem_number + 1]
        scoring_data = pd.read_csv(init_file)['scoring_points'][1:args.problem_number + 1]
        print(f"ğŸ“Š Loaded {len(instruct_data)} problems from {init_file}")
    except Exception as e:
        print(f"âŒ Error reading query file: {e}")
        return

    # å¤„ç†æ¯ä¸ªé—®é¢˜
    for i, item in enumerate(instruct_data):
        print(f"\\nğŸ”„ Processing problem {i+1}/{len(instruct_data)}")
        
        try:
            time_dict = extract_and_convert_datetime(item)
            data_time = time_dict['formatted_date']
            start_time = time_dict['start_timestamp']
            end_time = time_dict['end_timestamp']
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            trace_path = os.path.join(telemetry_folder, data_time, 'trace', 'trace_span.csv')
            metrics_path = os.path.join(telemetry_folder, data_time, 'metric', 'metric_container.csv')
            log_path = os.path.join(telemetry_folder, data_time, 'log', 'log_service.csv')
            
            print(f"   ğŸ“ Data time: {data_time}")
            print(f"   ğŸ“ Trace: {trace_path}")
            print(f"   ğŸ“ Metrics: {metrics_path}")
            print(f"   ğŸ“ Logs: {log_path}")
            
            # éªŒè¯æ•°æ®æ–‡ä»¶å­˜åœ¨
            for path in [trace_path, metrics_path, log_path]:
                if not os.path.exists(path):
                    print(f"   âš ï¸  Warning: {path} not found")
            
            # ä½¿ç”¨ tkg_from_openrca å¤„ç†
            print(f"   ğŸ”„ Running tkg_from_openrca...")
            test_list, top_info = tkg_from_openrca(
                traces_path=trace_path,
                logs_path=log_path,
                metrics_path=metrics_path,
                incident_id=args.incident_id,
                window={"start": start_time, "end": end_time} if (start_time or end_time) else None,
            )
            
            print(f"   ğŸ“Š Generated {len(test_list)} time slices")
            
            # å¯¼å‡ºç»“æœ
            for ts_time, kg in test_list:
                time = parse_opencra_timestamp(str(ts_time))
                time_str = time.strftime("%H-%M-%S")
                
                # åˆ›å»ºè¾“å‡ºç›®å½•
                base = Path(args.outdir) / args.dataset / data_time / time_str
                base.mkdir(parents=True, exist_ok=True)
                
                # è¾“å‡ºæ–‡ä»¶è·¯å¾„
                graphml = base / f"{args.incident_id}.graphml"
                nodes_csv = base / f"{args.incident_id}.nodes.csv"
                edges_csv = base / f"{args.incident_id}.edges.csv"
                summary_path = base / f"{args.incident_id}.summary.json"
                
                # å¯¼å‡ºæ•°æ®
                kg.to_csv(nodes_csv, edges_csv)
                with open(summary_path, "w") as f:
                    json.dump(kg.summary(), f, indent=2, default=str)
                
                try:
                    kg.to_graphml(graphml)
                except Exception as e:
                    print(f"   âš ï¸  Warning: Could not export GraphML: {e}")
                
                print(f"   ğŸ“¤ Exported to: {base}")
                print(f"      - Nodes: {nodes_csv}")
                print(f"      - Edges: {edges_csv}")
                print(f"      - Summary: {summary_path}")
                
                # å¯¼å‡ºä¿®å‰ªåçš„CSV
                try:
                    nodes_csv_trim, edges_csv_trim = export_trimmed_csv(kg, nodes_csv, edges_csv)
                    print(f"      - Trimmed: {nodes_csv_trim}, {edges_csv_trim}")
                except Exception as e:
                    print(f"   âš ï¸  Warning: Could not export trimmed CSV: {e}")
                
                # æ‰“å°å›¾è°±æ‘˜è¦
                summary = kg.summary()
                print(f"   ğŸ“Š Graph summary: {summary['nodes']} nodes, {summary['edges']} edges")
        
        except Exception as e:
            print(f"   âŒ Error processing problem {i+1}: {e}")
            continue
    
    print(f"\\nâœ… Processing complete!")

if __name__ == "__main__":
    main()
'''
    
    return fixed_script

def create_config_file():
    """åˆ›å»ºé…ç½®æ–‡ä»¶"""
    config_content = '''# KG-RCA2 Configuration
# æ•°æ®è·¯å¾„é…ç½®
data:
  root: "./data"  # æ•°æ®æ ¹ç›®å½•
  datasets:
    - "Bank"
    - "Telecom"
    - "E-commerce"
  
# è¾“å‡ºé…ç½®
output:
  root: "./outputs"  # è¾“å‡ºæ ¹ç›®å½•
  format: ["csv", "graphml", "json"]  # è¾“å‡ºæ ¼å¼
  
# å¤„ç†é…ç½®
processing:
  max_problems: 10  # æœ€å¤§å¤„ç†é—®é¢˜æ•°
  time_window: 3600  # æ—¶é—´çª—å£(ç§’)
  minute_bucket: true  # æ˜¯å¦æŒ‰åˆ†é’Ÿåˆ†æ¡¶
  
# æ€§èƒ½é…ç½®
performance:
  memory_limit: "4GB"  # å†…å­˜é™åˆ¶
  batch_size: 1000  # æ‰¹å¤„ç†å¤§å°
  parallel: false  # æ˜¯å¦å¹¶è¡Œå¤„ç†
'''
    
    return config_content

def create_env_example():
    """åˆ›å»ºç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶"""
    env_content = '''# KG-RCA2 Environment Variables
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶ä¿®æ”¹ç›¸åº”å€¼

# æ•°æ®è·¯å¾„
KG_RCA_DATA_ROOT=./data
KG_RCA_OUTPUT_ROOT=./outputs

# æ•°æ®é›†é…ç½®
KG_RCA_DATASET=Bank
KG_RCA_MAX_PROBLEMS=1

# æ€§èƒ½é…ç½®
KG_RCA_MEMORY_LIMIT=4GB
KG_RCA_BATCH_SIZE=1000
KG_RCA_PARALLEL=false

# è°ƒè¯•é…ç½®
KG_RCA_DEBUG=false
KG_RCA_VERBOSE=true
'''
    
    return env_content

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ ä¿®å¤ KG-RCA2 è·¯å¾„é—®é¢˜")
    print("=" * 50)
    
    # åˆ›å»ºä¿®å¤åçš„è„šæœ¬
    fixed_script = create_fixed_build_script()
    
    # å†™å…¥ä¿®å¤åçš„è„šæœ¬
    script_path = "/Users/yiyang/Documents/Code/RCA/KG-RCA2/build_kg_for_openrca_fixed.py"
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(fixed_script)
    
    print(f"âœ… åˆ›å»ºä¿®å¤åçš„è„šæœ¬: {script_path}")
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config_path = "/Users/yiyang/Documents/Code/RCA/KG-RCA2/config.yaml"
    with open(config_path, "w", encoding="utf-8") as f:
        f.write(create_config_file())
    
    print(f"âœ… åˆ›å»ºé…ç½®æ–‡ä»¶: {config_path}")
    
    # åˆ›å»ºç¯å¢ƒå˜é‡ç¤ºä¾‹
    env_path = "/Users/yiyang/Documents/Code/RCA/KG-RCA2/.env.example"
    with open(env_path, "w", encoding="utf-8") as f:
        f.write(create_env_example())
    
    print(f"âœ… åˆ›å»ºç¯å¢ƒå˜é‡ç¤ºä¾‹: {env_path}")
    
    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. è®¾ç½®ç¯å¢ƒå˜é‡:")
    print("   export KG_RCA_DATA_ROOT=./data")
    print("   export KG_RCA_OUTPUT_ROOT=./outputs")
    
    print("\n2. è¿è¡Œä¿®å¤åçš„è„šæœ¬:")
    print("   python build_kg_for_openrca_fixed.py --dataset Bank --problem_number 1")
    
    print("\n3. æˆ–è€…ç›´æ¥æŒ‡å®šæ•°æ®æ ¹ç›®å½•:")
    print("   python build_kg_for_openrca_fixed.py --dataset Bank --data-root ./data")

if __name__ == "__main__":
    main()
